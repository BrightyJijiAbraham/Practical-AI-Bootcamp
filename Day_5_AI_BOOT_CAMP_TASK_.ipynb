{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 5 AI BOOT CAMP TASK .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LKIOr6yBgK"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "print(tfds.list_builders())\n",
        "\n",
        "dataloader = tfds.load(\"cifar10\", as_supervised=True)\n",
        "train, test = dataloader[\"train\"], dataloader[\"test\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_AZCbsOy86_"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
        "\n",
        "file_paths = [\n",
        "    tf.keras.utils.get_file(file_name, directory_url + file_name)\n",
        "    for file_name in file_names\n",
        "]\n",
        "\n",
        "dataset = tf.data.TextLineDataset(file_paths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRkyIVzL0ybQ"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR7H74uX1QlX",
        "outputId": "36635424-9cd9-49c6-ca9e-ba42c915ff10"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
        "\n",
        "file_paths = [\n",
        "    tf.keras.utils.get_file(file_name, directory_url + file_name)\n",
        "    for file_name in file_names\n",
        "]\n",
        "\n",
        "dataset = tf.data.TextLineDataset(file_paths)\n",
        "for line in dataset.take(5):\n",
        "  print(line.numpy())\n",
        " \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\"\n",
            "b'His wrath pernicious, who ten thousand woes'\n",
            "b\"Caused to Achaia's host, sent many a soul\"\n",
            "b'Illustrious into Ades premature,'\n",
            "b'And Heroes gave (so stood the will of Jove)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "qGH5mG9G1cLr",
        "outputId": "9c691da0-3adc-4b4a-bcbc-0e52246bdf66"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwoG3Ghs1kgE"
      },
      "source": [
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataloader = tfds.load(\"cifar10\", as_supervised=True)\n",
        "train, test = dataloader[\"train\"], dataloader[\"test\"]\n",
        "\n",
        "train = train.map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ").cache().map(\n",
        "    lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
        ").map(\n",
        "    lambda image, label: (tf.image.random_contrast(image, lower=0.0, upper=1.0), label)\n",
        ").shuffle(\n",
        "    100\n",
        ").batch(\n",
        "    64\n",
        ").repeat()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzKFkK513Vq"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
        "\n",
        "file_paths = [\n",
        "    tf.keras.utils.get_file(file_name, directory_url + file_name)\n",
        "    for file_name in file_names\n",
        "]\n",
        "\n",
        "dataset = tf.data.TextLineDataset(file_paths)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC6wtKXEQtWx"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "earlystop_callback = EarlyStopping(\n",
        "  monitor='val_accuracy', min_delta=0, patiece=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onBrem8zRDW6"
      },
      "source": [
        "def __init__(self, batch_size, num_patches, **kwargs):\n",
        "        super(TemporalReshape, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_patches = num_patches"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YA52HuPROWt"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "earlystop_callback = EarlyStopping(\n",
        "  monitor='val_accuracy', min_delta=0, patiece=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyc5sIZYRpI0"
      },
      "source": [
        "model.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[earlystop_callback])\n",
        "model.evaluate(ds_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy-u2d1nRwcp"
      },
      "source": [
        "model.save('saved_model/model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2UmNM30R1kQ"
      },
      "source": [
        "model = tf.keras.models.load_model('saved_model/model')\n",
        "\n",
        "def predict(image, model=model):\n",
        "    img = tf.keras.preprocessing.image.load_img(\n",
        "        image, target_size=(28, 28), color_mode='grayscale')\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img = tf.expand_dims(img, 0)\n",
        "    pred = model.predict(img)\n",
        "    score = tf.nn.softmax(pred[0])\n",
        "    return np.argmax(score)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}